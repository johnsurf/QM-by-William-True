\section{\underline{One Dimensional Harmonic Oscillator}}

1. \underline{Review}

First let us review the standard treatment of the linear harmonic oscillator in the coordinate representation which you can find in practically all text books of Quantum Mechanics, e.g, Pauling \& Wislon or Schiff pp. 67 ff. I will assume that you 
have already done this in a more elementary course in Quantum Mechanics and so I'll only review the more important aspects here. 

The harmonic oscillator or something closely related to it is forever appearing the physics of all types of phenomena -- mechanics, E \& M, solid state, etc. -- and is often used as the starting point to solving more complicated sytems. 

Our Hamiltonian is
$$H = {p^2\over 2m} + \half k x^2 = {p^2\over 2m}  + \half  m \omega^2 x^2  \mbox{   where  } \omega^2\equiv {k \over m}.$$
Since $H$H is time independent, we can write $\ds \Psi(x,t) = \psi(x)e^{-{iEt\over\hbar}}$ and our wave equation 
$$H\Psi(x,t) = i\hbar{\partial \over \partial t}\Psi(x,t)$$ reduces to 
$$H\psi(x) = E \psi(x) \mbox{   or  } \left( {\hbar^2\over 2m}{d^2\over dx^2} + E - \half m \omega^2 x^2 \right)\psi(x) = 0.$$
At this point, it is convenient to change variables and we define
$$E = \lambda\left({\hbar\omega\over 2}\right) \mbox{    and    } x = \xi\sqrt{ {\hbar\over m \omega}}.$$
Our differential equations becomes
$${d^2 \psi(\xi)\over d\xi^2} + (\lambda - \xi^2)\psi(\xi) = 0.$$
For large $\xi$ we can neglect $\lambda$ and we see that our solution goes like $\ds e^{-{\xi^2\over 2}}$. So we look for a solution of the form
$$\psi(\xi) = \phi(\xi)\exp^{-{\xi^2\over 2}}$$ which gives us a differential equation of 
$${d^2\phi\over d\xi^2} - 2\xi {d\phi\over d\xi} + (\lambda - 1)\phi = 0.$$
Now a standard approach is to try a series solution of the form
$$\psi(\xi) = \xi^s(b_o + b_1 \xi + b_2\xi^2 \hdots)\mbox{   where } b_0 \ne 0.$$
Substituting this solution into the differential equation we find by equating each coefficient of each power of $\xi$ to zero that $s = 0\mbox{  or } 1$ from the 1st equation and so $s=0 \mbox{ and/or } b_1 =0$ from the 2nd
equation. The succeeding equations five use recursion relations so that we have
\begin{eqnarray*}
\phi(\xi) &=& a_0 + a_2 \xi^2 + a_4 \xi^4 + \hdots \mbox{   for } s = 0  \mbox{ and}\\ 
\phi(\xi) &=& a_1\xi + a_3 \xi^3 + a_5 \xi^5 + \hdots \mbox{   for } s = 1  \mbox{ with}\\
a_{k+2} &=& {2k -\lambda + 1\over (k+1)(k+2)} a_k.
\end{eqnarray*}

One can quite easily show that both solutions $\ds \psi(\xi) = \exp^{-{lxi^2\over2}}\phi(xi)$ $\mbox{ for } s=0 \mbox{ or } 1$ diverge as $x\goes \pm \infty$.But this is not acceptable as $\psi(x)$ must remain finite.
$\psi(x)$ can only remain finite if $\phi(\xi)$ is a finite series which will occur if $\lambda$ is restricted to only take on the values $2n + 1$ where $n=0,1,2,\hdots$. This restricts the possible values of $E$ and we find
the quantized energy eigenvalues of $$E_n = (n + \half)\hbar\omega.$$
By picking the two arbitrary constants $a_0$ and $a_1$ ``correctly'', the $phi(\xi)$'s become the Hermite polynomials:
\begin{eqnarray*}
H_0(\xi) &=& 1\\
H_1(\xi) &=& 2\xi\\
H_2(\xi) &=& 4\xi^2 - 2i\\
H_3(\xi) &=& 8\xi^3 - 12\xi2i\\
\hdots &\null& \hdots\\
H_n(\xi) &=& (-1)^n \exp^{{\xi^2\over 2}}{d^n e^{-\xi^2}\over d\xi^n}.
\end{eqnarray*}
$H_n(\xi)$ satisfies the differential equation of $\phi(\xi)$ with $\lambda = 2n+1$, viz. 
$$H_n'' - 2\xi H'_n + 2n H_n = 0.$$
One can also show that 
\begin{eqnarray*}
H'_n &=& 2n H_{n-1}\\
0 &=& H_{n+1} - 2\xi H_n + 2n H_{n-1}\\
H_{n+1} &=& 2\xi H_n - H'_n
\end{eqnarray*}
In fact, one can take this last equation along with $H_0(\xi) = 1$ and ``generate'' all the other $H_n$'s. 

One can also use a generating function to obtain the $H_n$'s. The generating function $g(\xi,h)$ is given by
$$g(\xi,h) = e^{2\xi h - h^2} = \sum_{n=0}^\infty\, {H_n(\xi)h^n\over n!}.$$
The $H_n$'s are obtained by expanding $\ds e^{2\xi h - h^2}$ and equating coefficients of like powers of $h$ on both sides. These generating functions are vey useful in evaluating integrals involving the $H_n$'s. 

One usually normalizes $\psi(x)$ to unity by
$$\ket{n} \equiv \psi_n(\xi) = {1\over\sqrt{2^n n!\sqrt{\pi}}}e^{-{\xi^2\over 2}} H_n(\xi)$$ and then 
$$\int\, \psi^*_n(x) \psi_m(x)\, dx = \sqrt{{\hbar\over m\omega}} \int\, \psi^*_n(\xi) \psi_m(\xi)\, d\xi = \delta_{nm}\mbox{  and}$$
$$H\psi_n(\xi) = E_n\psi_n(\xi).$$
The matrix elements $\xAy{n}{H}{m}$ form a diagonal matrix in the coordinate representation
\[ H = \begin{pmatrix}
\half\hbar\omega & 0  & 0 & 0& 0& \hdots  \\
0  & {3\over2} \hbar\omega & 0&  0& 0& \hdots  \\
0 & 0   & {3\over2}\hbar\omega& 0& 0& \hdots \\
0 & 0   & 0 & {7\over2}\hbar\omega & 0& \hdots \\
\hdotsfor[2]{6}\\
\end{pmatrix} \]
and one can show that 
\[ \xi  = \begin{pmatrix}
0 & \sqrt{1\over2} & 0  & 0 & 0& 0& \hdots  \\
\sqrt{1\over2} & 0  & \sqrt{2\over2} & 0&  0& 0& \hdots  \\
0& \sqrt{2\over2}  & 0   & \sqrt{3\over2}& 0& 0& \hdots \\
0& 0 & \sqrt{3\over2}   & 0 & \sqrt{4\over2} & 0& \hdots \\
\hdotsfor[2]{7}\\
\end{pmatrix} \]

\subsection{\underline{2. An Alternatice Approach}}
After this quick review of the harmonic oscillator, I now want to show you what I promised earlier. That is, given the fundamental observables of the system and their commutation relations, I can 
solve this system without ever going into a representation. In fact, one should always be able to do this in principle but it is generally not easy to do so in practive. 

In this case, our fundamental observables are $p$ and $q$ (I will now use $q$ instead of $x$) and we have
$$\left[ p,p\right] = \left[q,q\right] = 0\mbox{   and  } \left[q,p\right] = i\hbar.$$
All our observables and/or operators are functions of $p$ and $q$. In particular
$$H = {p^2\over2m} + \half m\omega^2 q^2 = .$$
Instead of using $p$ and $q$, it is more conventient to introduce two other operators $R^\dagger$ and $R$ where 
\begin{eqnarray*}
R^\dagger &\equiv& {1\over\sqrt{2m\omega\hbar}}(m\omega q - ip)\mbox{~~~~~        and} \\
R               &\equiv& {1\over\sqrt{2m\omega\hbar}}(m\omega q + ip)
\end{eqnarray*}
or inversely
\begin{eqnarray*}
q &=& \sqrt{\hbar\over2m\omega} (R^\dagger + R)\mbox{~~~~~         and } \\
p &=& \sqrt{m\omega\hbar\over2} (R^\dagger  - R)
\end{eqnarray*}

Using $[q,p] = i\hbar$, we find that 
$$[R,R^\dagger] = 1, \quad [R^\dagger, R^\dagger] = 0, \mbox{~~~~~and } [R,R] = 0.$$
For $H$, we find 
$$H = (R^\dagger R + \half)\hbar\omega = (R^\dagger R + RR^\dagger){\hbar\omega\over2}.$$
So our eigenvalue equaton
$$H\ket{\Psi} = E\ket{\Psi}$$ reduces to solving an eigenvalue equation for
$R^\dagger R$. That is, if we can solve 
$$R^\dagger R \ket{n} = \lambda_n \ket{n}$$ then due to the form of $H$, we can certainly find $E_n$ in 
$$H\ket{n} = E_n \ket{n}.$$ 

First we show that $\lambda_n$ is non-negative. For this, consider $\ket{\chi} \equiv R\ket{n}$. Then 
$$\braket{\chi}{\chi} = \xAy{m}{R ^\dagger R}{n}  = \lambda_n\braket{n}{n}$$ and since $\braket{\chi}{\chi}$ and $\braket{n}{n}$ are positive definite, we need
$$\lambda_n \ge 0.$$

Next we look at
$$\ket{\chi} \equiv R^\dagger \ket{n}$$ and operate on it with $R^\dagger R$. Then
\begin{eqnarray*}
R^\dagger R\ket{\chi} &=& R^\dagger R R^\dagger\ket{n} = R^\dagger(1+ R^dagger R)\ket{n} = R^\dagger(1+\lambda_n)]ket{n}\\
                                    &=& (\lambda_n + 1)(R^\dagger\ket{n}) = (\lambda_n + 1) \ket{\chi}.
\end{eqnarray*}

So we see that $\ket{\chi} = R^\dagger \ket{n}$ is an eigenket of $R^\dagger R$ with an eigenvalue $(\lambda_n + 1)$. Likewise $R^\dagger R^\dagger \ket{n}$ is an eigenket with 
eigenvalue $(\lambda_n+2)$. Thus, given $\ket{n}$, we can ``generate'' all the higher eigenkets of $R^\dagger R$.

In a like manner, we can show that $R\ket{n}$ is also an eigenfunction of $R^\dagger R$ with an eigenvalue of $\lambda_n-1$...and so forth for $RR\ket{n}$, $RRR\ket{n}, \hdots$. 
While we could increase $\lambda_n$ indefinitely by using $R^\dagger$'s, we cannot reduce it indefinitely by using $R$'s as we must satisfy $\lambda_n \ge 0$ and so we cannot have
negative eigenvalues. If we operate on each successively smaller eigenket with $R$, we will eventually reach the eigenket with the ``lowest possible'' eigenvalue. 
Let's call this eigenket $\ket{\lambda_0}$. Then upon operating with $R$ again, we must have
$$R\ket{\lambda_0} = 0$$ or otherwise we will generate an eigenket with a lower eigenvalue which will be a contradiction. Now $\lambda_0$ is somewhere between zero and one. We have
$$R^\dagger R\ket{\lambda_0} = \lambda_0\ket{\lambda_0} \mbox{~~~~~ and } R\ket{\lambda_0} = 0.$$
But $R^\dagger R\ket{\lambda_0} = R^\dagger (R\ket{\lambda_0}) = R^\dagger (0) = 0$ which tells us that $\lambda_0 = 0$ uniquely.







