\section{215A - Introduction and Review}

I will assume that you all have had at least one quarter or one semester of undergraduate quantum mechanics.
This means that you have been introduced to the wave function $\Psi(\vec r,t)$ and the Schr\"odinger wave equations, 
$H\Psi = i\hbar {\partial \Psi\over \partial t}$,which tells us how $\Psi$ develops in time. You should have solved the wave
equation for the one-dimensional harmonic oscillator, the hydrogen atom, and particles incidents on square potential steps.
You probably have also seen or been exposed to many other things.\\

During this course, we will cover some of the material which you have seen before. But it will be more in the way of a review.\\

The first part of the course will deal more with various mathematical aspects which relate to quantum mechanics. We will use these things to 
formulate quantum mechanics in a more general, more powerful, and more useful way than the Schr\"odinger picture allows.\\

There are relatively few systems which can be solved exactly. There are even fewer systems in the ``real'' world which can 
be solved exactly. So we must resort to approximations in order to describe the physical systems. Much of this course will 
be devoted to the study of various approsimations and to when and where they can be used. \\

Later on we will look at some relativistic quantum mechanics and the second quantization picture.\\ 

I will not follow any textbook in detail, but much of what I say can be found in Schiff, Messiah, and Boym -- and in many other books as well.\\

I hope the homework will ``fill in'' some of the gaps in my lectures and give you a better understanding of the methods and techniques used
in quantum mechanics.
 
\subsection{$\Psi(\vec{r},t)$  and $\Phi(\vec{p},t)$ }
 \centerline{A Quick Review of Some Points}
  
 Usually in a beginning course, one works in the coordinate represenation. We shall see shortly that quantum mechanics can be formulated more
 generally in a more useful and powerful way by using an abstract vector space known as Hilbert Space. Then our system will be described by a 
 vector in Hilbert Space. As our system evolves in time, this vector will mover around in ``our'' Hilbert Space. \\
 
 In the coordinate represenation, the state of a ``single'' particle system is described by a wave function, $\Psi(\vec{r},t)$, with $|\Psi|^2 d\vec{r}$ being
 the probability that at time $t$, the particle will be found in the volume $d\vec{r} = dx\,dy\,dz$ at $\vec{r}$. $\Psi(\vec{r},t)$ is a complex function
 and must be if $\Psi(\vec{r},0)$ along with the wave equation is to determine $\Psi(\vec{r},t)$ at some later time -- including the boundary conditions, 
 of course, (cf. Merzbacher pp. 14-18).\\

We will generally only consider non-relativistic cases for the first part of the course fo that we do not have to concern ourselves about creation
and annihilation of particles and other relativistic effects.\\

A restriction on \Wftn\ is that is must be ``square integrable'', i.e., $\IntPsiSq$ is a finite real number (It belongs to a Hilbert space). Often, one normalizes
$\Psi$ such that $\IntPsiSq = 1$, although it is not necessary and, in some cases, not desirable. For example, the plane wave
$$\Psi = N e^{i(k\cdot r - \omega t)}$$ is not square integrable and couldn't be used as a wave function to describe a moving particle. However, this
plane wave can and oftern is used to describe a steady flux of particles. 

\subsection{ $\Psi(\vec r, t) \rightleftharpoons \Phi(\vec p, t)$ via Fourier Transforms}
Instead of working in the coordinate representation. we could also work in the momentum
representation.\\

In this case, the wave function is $\Phi(\vec{p},t)$ where $|\Phi|^2\, d\vec{p}$ is the probability of finding the particle with momentum $\vec{p}$ in the volume
$d\vec{p}$ at time $t$. \\

$\Psi$ and $\Phi$ are connected to each other and are Fourier transforms of each other. That is, 

 \begin{eqnarray*}
  \Phi(\vec{p},t) &=& {1\over (2\pi\hbar)^{3/2}} \int_0^\infty \, \Psi(\vec{r},t)e^{-i\vec{p}\cdot\vec{r}/\hbar}\, d\vec{r} \\ 
  \hbox{and~~~~~~~~~~~~~~~\hfill} &\null&\\
  \Psi(\vec{r},t) &=& {1\over (2\pi\hbar)^{3/2}} \int_0^\infty \, \Phi(\vec{p},t)e^{-i\vec{p}\cdot\vec{r}/\hbar}\, d\vec{p} 
 \end{eqnarray*}Usually, one uses $\vec{p} = \hbar\vec{k}$ and ``defines'' a $\Phi(\vec{k},t)$ instead of $\Phi(\vec{r},t)$ such that 
  
 \begin{eqnarray*}
  \Phi(\vec{k},t) &=& {1\over (2\pi)^{3/2}} \int_0^\infty \, \Psi(\vec{r},t)e^{-i\vec{p}\cdot\vec{r}}\, d\vec{r} \\ 
  \hbox{and~~~~~~~~~~~~~~~~~~\hfill} &\null&\\
  \Psi(\vec{r},t) &=& {1\over (2\pi)^{3/2}} \int_0^\infty \, \Phi(\vec{k},t)e^{-i\vec{k}\cdot\vec{r}}\, d\vec{p} 
 \end{eqnarray*}Remember that neither $\Psi$ nor $\Phi$ can be measurable but only the magnitude of the amplitudes.\\
 
 How is $|\Psi|^2$ related to the measurement of a particle since a measurement places a particle at a definit point in space? What one does is to 
 ``prepare'' a large number of identical systems and measure the position of the particle for each system. The measurements will yield a ``distribution'' of
 positions and this distribution will approach $|\Psi|^2$ as the number of measurements become very large. Similar remarks can be made concerning
 the distribution of $|\Phi|^2$. \\
 
 \subsection{The Hamiltonian and the Wave Equation}
 The Schr\"odinger wave equation tells us how $\Psi(\vec{r},t$ develops in time. Classically, one has for an isolated system of particles that 
 $$H(q_1,...q_N,p_1,...p_N,t) = E.$$ The wave equation is given by $$H\Psi = i\hbar{\partial \Psi\over \partial t}$$ where in $H$ all the $p_i$'s are to be
 replaced by ${\hbar\over i}{\partial\over \partial q_i}$.\\
 
 Now one must be careful in following the above prescription. First, $H$ must be written in terms of Cartesian coordinates and their corresponding conjugate
 momenta. For example, if $H$ was written in terms of spherical polar coordinates and one replaced $p_r$ by ${\hbar\over i}{\partial \over \partial r}$, $p_\theta$ by 
 ${\hbar\over i}{\partial \over \partial\theta}$, and $p_\phi$ by ${\hbar\over i}{\partial\over \partial \phi}$, one would not obtain the correct wave equation.\\
 
 Secondly, one must properly symmeterize the combinations of $q_i$ and $p_i$. For example, $pq$ and $qp$ are the same classically but not quantum mechanically.
 i.e., $pq\Psi = {\hbar\over i} {\partial\over q} (q\Psi) \ne qp \Psi = q {\hbar\over i} {\partial\over q} \Psi$. In this case, $pq$ must be replaced by the symmetrized expression
 ${1\over2}(pq + qp)$. To the best of my knowledge, all classical Hamiltonians are such that they can be readily ``symmetrized'' in the above manner. \\
 
 We will also encounter systems which have observables which have no classical analogue, e.g., intrinsic spin. In order to write down
 the Hamiltonian operators, one will have to introduce the operators associated with these ``new'' observables in a consistent manner. We will discuss
 this point shortly and only mention here that it is sufficient to give the commutation properties of these new operators with all the other operators
 of the system.\\

 \subsection{Probability Density and Probability Current}
 We define the ``probability density'' $P$ as $P = |\Psi(\vec{r},t)|^2 = \Psi^*(\vec{r},t) \Psi(\vec{r},t)$. Its time rate of change is 
 $${\partial P\over \partial t} = \Psi^*{\partial \Psi\over \partial t} + \big( {\partial \Psi^*\over \partial t} \big)\Psi$$and using 
 $H\Psi = i\hbar {\partial \Psi\over \partial t}$,  we have with $H = {p^2\over 2m} + V(\vec{r})$
 $${\partial P\over \partial t} = -{\hbar\over2m i} \hbox{div}\big\{\Psi^*\nabla \Psi - \Psi \nabla\Psi^* \big\}.$$This can be written as
 $$\hbox{div}\vec{S} + {\partial P\over \partial t} = 0$$by defining the ``probability current'' $\vec{S}$ as
 $$\vec{S} = -{\hbar\over2m i} \big(\Psi^*\nabla \Psi - \Psi \nabla\Psi^* \big).$$$\vec{S}$ describes the ``flow'' of probability density $P=|\Psi|^2$ just as
 $\rho \vec{v}$ describes the density flow in the hydrodynamic case by the equation
 $$\hbox{div}(\rho\vec{v}) + {\partial \rho\over \partial t} = 0.$$\\
  Knowing $\Psi$ and $\Phi$ we can now write down expressions which tell us what the mean values of measurements for functions like
 $F(\vec{r})$ and $G(\vec{p})$ will be. That is 
 \begin{eqnarray*}
  \langle F(\vec{r})\rangle  &=& \int  \, |\Psi|^2\, F(\vec{r})\,d\vec{r} \\ 
  \hbox{and~~~~~~~~~~~~~~~~~~\hfill} &\null&\\
  \langle G(\vec{p})\rangle  &=& \int  \, |\Phi|^2\, G(\vec{p})\,d\vec{p}.
 \end{eqnarray*}\\
 
 Since $\Psi$ and $\Phi$ are Fourier transforms of each other which we assume to vanish at infinity, we can always evaluate $F(\vec{r}$ in the momentum representation and/or $G(\vec{p})$ in the coordinate representation. In particular. one can show quite easily that 
  \begin{eqnarray*}
  \langle \vec{p}\rangle  &=& \int  \, |\Psi^*(\vec{r},t)\, \left( {\hbar\over i} \nabla_r\right) \Psi(\vec{r},t)\,d\vec{r}\\
  \hbox{and~~~~~~~~~~~~~~~~~~\hfill} &\null&\\
  \langle \vec{r}\rangle  &=& \int  \, |\Phi(\vec{p},t)\, \left( {\hbar\over i} \nabla_p\right) \Phi(\vec{p},t)\,d\vec{p}. 
 \end{eqnarray*}\\

Now all the $\Psi$'s describing a system will form a Hilbert space which we know is a linear space. For example, if $\Psi_1$ and $\Psi_2$ belong to this space, then does $$\lambda_1\Psi_1 + \lambda_2\Psi_2$$ belong to this space where $\lambda_1$ and $\lambda_2$ are arbitrary complex numbers. 

\subsection{Scalar Products}
In this space we define a ``scalar product'' as 
$$\langle \phi,\psi\rangle  \equiv (\phi,\psi) \equiv \int \phi^*\psi\, d\tau$$ where by the last expression I am implying some specific representation, e.g., in the coordinate representation, $\phi$ and $\psi$ are functions of $\vec{r}$ and $d\tau = d\vec{r}$. The norm will be defined as $\sqrt{\langle \psi,\psi\rangle }$. If $\sqrt{\langle \psi,\psi\rangle } = 1$, the state is said to be normalized. \\
If $\braket{\phi}{\psi} = 0$ with $\phi \ne 0$ and $\psi \ne 0$, the two states described by $\phi$ and $\psi$ are said to be orthonormal.\\
Some further properties of out scalar product properties are by definition:\\
1. $\braket{\phi}{\psi}^* = \braket{\psi}{\phi}$\\
2. $\braket{\phi}{\lambda_1 \psi_1 + \lambda_2 \psi_2} = \lambda_1\braket{\phi}{\psi_1} + \lambda_2\braket{\phi}{\psi_2}$\\
3. $\braket{\psi}{\psi} \ge 0$ and $\braket{\psi}{\psi} = 0 \iff \psi = 0$\\
4. Hermitian conjugate of an operator. \\
In general, when an operator $A$ operates on a wave function, it changes it into another wave function, e.g., $A\psi = \psi'$.
$A^\dagger$ will be defined as the ``Hermitian conjugate'' of the operator $A$ and has the property that 

$$ \braket{\phi}{A\psi} \equiv \braket{A^\dagger \phi}{\psi}$$

If $A^\dagger = A$, $A$ is said to be a Hermitian Operator. The expectation value of all Hermitian Operators are real. That is 
$$ \expect{A} \equiv \expect{\psi,A\psi} = \expect{A^\dagger\psi,\psi} = \expect{A\psi,\psi} = \expect{\psi,A\psi}^*$$
Therefore $\expect{A}$ is real. 

Using properties 1, 2, and 3 above, one can derive Schwarz's inequality which states that 

\[ \expect{\phi,\phi}\expect{\psi,\psi} \ge |\expect{\phi,\psi}|^2 \] with the equality sign holding iff $\phi = \lambda \psi$,

There are many operators in quantum mechanics, but all operators corresponding to observables, e.g, position, linear momentum, 
angular momentum, etc., are Hermitian operators. The measurement of an observable $A$ will generally give a ``spread'' or ``distribution''
of values of $A$. We define the ``uncertainty'' in $A$ as $\Delta A$ where 
\[ (\Delta A)^2 = \expect{A^2} - \expect{A}^2. \]
If $\Delta A = 0$, a restriction is placed on the expression $A\psi$ where, of course, $A$ is an Hermitian operator. The expectation 
value of $A$ is \[ \expect{A} = { \expect{\psi,A\psi}\over \expect{\psi,\psi}}\] which reduces to $\expect{\psi, A\psi}$ if $\psi$ is normalized.
If $\Delta A = 0$, we have 
\[ { \expect{\psi, A^2 \psi} \over \expect{\psi,\psi}} = { \expect{\psi,A\psi}^2\over \expect{\psi,\psi}^2} \] and as 
$\expect{\psi,A^2 \psi } = \expect{A\psi,A\psi},$ we have 
\[ \expect{\psi,\psi}\expect{A\psi,A\psi} = \expect{\psi,A\psi}^2. \] \\

This is just Schwarz's inequality with $\phi = A\psi$ and the equality sign holding. Thus $\phi = a\psi$ where $a$ is a complex constant
in general. So $A \psi = a\psi$ and then $\expect{A} = a$. But $A$ is an Hermitian operator and so $\expect{A}$ and therefore $a$ is real.\\

Using $\psi_a$ instead of $\psi$ above, we have that whenever $\Delta A = 0, A\psi_a = a \psi_a$. This is called an eigenvalue equation
with $a$ the ``eigenvalue'' of the operator $A$ and $\psi_a$ the ``eigenfunction''.\\

$e^{ {ipx / \hbar}}$ is an eigenfunction of the operator $P_x$. i.e., 

\[ P_x e^{ipx/\hbar} = {\hbar\over i} {\partial \over \partial x} e^{\i px/\hbar} = p e^{ipx/\hbar}.\]

But this eigenfunction is not square integrable and does not belong to our Hilbert space. Note that this eigenfunction had a continuous (and not
a discrete) spectrum.\\

Now it is quite easy to show that two eigenfunctions of the operator $A$ with different eigenvalues are orthogonal and linearly independent. To 
show this, consider 

\begin{eqnarray*}
A \psi_a&=&a \psi_a \quad \hbox{and} \\
A \psi_b&=&b \psi_b\\
\end{eqnarray*} 

Now
\[ \expect{\psi_b, A \psi_a} - \expect{\psi_a, A\psi_b}^* = (a - b)\expect{\psi_b,\psi_a},\]
note that $\expect{\psi_b,A\psi_b}^* = \expect{\psi_b,A\psi_a}$. Therefore
$(a-b)\expect{\psi_b,\psi_a} = 0$ and so $\expect{\psi_b,\psi_a} = 0$ if $a\ne b$. \\

To be linearly dependent we need to find non-zero $\lambda_a$ and $\lambda_b$ such that $\lambda_a \psi_a + \lambda_b \psi_b = 0$. 
Taking the scalar product of this last expression with $\psi_a$, we have 

\[ \lambda_a \expect{\psi_a,\psi_a} + \lambda_b \expect{\psi_a,\psi_b} = 0,\] or $\lambda_a \expect{\psi_a,\psi_a} = 0$. But if $\psi_a\ne 0$, we need
$\lambda_a = 0$. Likewise, $\lambda_b = 0$ and so $\psi_a$ and $\psi_b$ are linearly independent. \\

We see that ``non-degenerate'' eigenfunctions are orthogonal. If the eigenvalues are equal, it is not clear whether or not they are orthogonal. However,
they can be made orthogonal by the 	``Schmidt orthogonality process'' which goes as follows:\\

Consider the set of eigenfunctions $\psi_1, \psi_2, \psi_3,..., \psi_N$ all of which have the same eigenvalues, i.e., eigenfunctions are all equal.

1. Take $\phi_1 = c_1 \psi_1$  and pick $c_1$ so that $\phi_1$ is normalized, i.e., $c_1^2 = 1/\expect{\psi_1,\psi_1}.$\\
2. Next take $c_2 \phi_2 = \psi_2 - \phi_1\expect{\phi_1,\psi_2}$.\\
In this case, we see that $\expect{\phi_1,\phi_2} = 0$ and we can pick $c_2$ such that $\expect{\phi_2,\phi_2} = 1$.\\
3. Next take $c_3 \phi_3 = \psi_3 - \phi_1\expect{\phi_1,\psi_3} - \phi_2\expect{\phi_2,\psi_3}$. We see that $\expect{\phi_1,\phi_3} = 0$ and $\expect{\phi_2,\phi_3} = 0$
and we pick $c_3$ such that $\expect{\phi_3,\phi_3} = 1$.\\
4,..,N Just continue on in this manner until one has a set of $\phi_1, \phi_2,..., \phi_N$ of orthonormal functions where $\expect{\phi_i, \phi_j} = \delta_{ij}$.   
   
